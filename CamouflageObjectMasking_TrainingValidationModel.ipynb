{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31e0c2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAMBHAVI SHANKER\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg \n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchsummary import summary\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1aa9978",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = 'cuda:0'\n",
    "else:\n",
    "    dev = 'cpu'\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a39bbe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataUpload:\n",
    "    \n",
    "    def __init__(self, images_path, masks_path):\n",
    "        self.image_path = images_path\n",
    "        self.mask_path = masks_path\n",
    "        self.images_array, self.masks_array = [], []\n",
    "    \n",
    "    def loadData(self):\n",
    "        for i in tqdm(os.listdir(self.image_path)):\n",
    "            image = os.path.join(self.image_path, i)\n",
    "            image = cv.imread(image)\n",
    "            \n",
    "            self.images_array.append(image)\n",
    "        \n",
    "        for m in tqdm(os.listdir(self.mask_path)):\n",
    "            mask = os.path.join(self.mask_path, m)\n",
    "            mask = cv.imread(mask)\n",
    "            \n",
    "            self.masks_array.append(mask)\n",
    "        \n",
    "        return self.images_array, self.masks_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74042c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allAboutData(train_images_path, train_masks_path, val_images_path, val_masks_path, val_fraction=0.6):\n",
    "    \n",
    "    trainLoader = dataUpload(train_images_path, train_masks_path)\n",
    "    train_images, train_masks = trainLoader.loadData()\n",
    "    \n",
    "    val_testLoader = dataUpload(val_test_images_path, val_test_masks_path)\n",
    "    val_test_images, val_test_masks = val_testLoader.loadData()\n",
    "    \n",
    "    def val_test_split(val_fraction):\n",
    "        val_test_zip = [[image, mask] for image, mask in zip(val_test_images, val_test_masks)]\n",
    "        \n",
    "        val_size = int(val_fraction * len(val_test_zip))\n",
    "        test_size = len(val_test_zip) - val_size\n",
    "        valset, testset = torch.utils.data.random_split(val_test_zip, (val_size, test_size), generator=torch.Generator().manual_seed(0))\n",
    "        \n",
    "        val_images, val_masks = [], []\n",
    "        test_images, test_masks = [], []\n",
    "\n",
    "        for val_elem in valset:\n",
    "\n",
    "            val_images.append(val_elem[0])\n",
    "            val_masks.append(val_elem[1])\n",
    "        \n",
    "        for test_elem in testset:\n",
    "\n",
    "            test_images.append(test_elem[0])\n",
    "            test_masks.append(test_elem[1])\n",
    "        \n",
    "        return val_images, val_masks, test_images, test_masks\n",
    "    \n",
    "    val_images, val_masks, test_images, test_masks = val_test_split(val_fraction)\n",
    "    return train_images, train_masks, val_images, val_masks, test_images, test_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2633f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeImages(images, masks, height, width):\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        images[i] = cv.resize(images[i], (width, height))\n",
    "        masks[i] = cv.resize(masks[i], (width, height))\n",
    "    \n",
    "    return images, masks\n",
    "\n",
    "def toGrayScale(images, masks):\n",
    "    gray_images, gray_masks = [], []\n",
    "    for image, mask in zip(images, masks):\n",
    "        gray_images.append(cv.cvtColor(image, cv.COLOR_BGR2GRAY))\n",
    "        gray_masks.append(cv.cvtColor(mask, cv.COLOR_BGR2GRAY))\n",
    "    \n",
    "    return gray_images, gray_masks\n",
    "\n",
    "def augmentImages(images, masks, translate, rotate):\n",
    "    if translate:\n",
    "        images, masks = translateData(images, masks)\n",
    "    if rotate:\n",
    "        images, masks = rotateData(images, masks)\n",
    "    \n",
    "    return images, masks\n",
    "\n",
    "def translateData(images, masks):\n",
    "    translated_images, translated_masks = [], []\n",
    "    \n",
    "    for image, mask in zip(images, masks):\n",
    "        translated_img, translated_mask = translateImage(image, mask)\n",
    "        translated_images.append(translated_img)\n",
    "        translated_masks.append(translated_mask)\n",
    "    \n",
    "    return images + translated_images, masks + translated_masks\n",
    "\n",
    "def rotateData(images, masks):\n",
    "    rotated_images, rotated_masks = [], []\n",
    "    \n",
    "    for image, mask in zip(images, masks):\n",
    "        rot_img, rot_mask = rotateImage(image, mask)\n",
    "        rotated_images.append(rot_img)\n",
    "        rotated_masks.append(rot_mask)\n",
    "    \n",
    "    return images + rotated_images, masks + rotated_masks\n",
    "\n",
    "def translateImage(image, mask):\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    translate_value = np.random.rand() / 2\n",
    "    width_translate, height_translate = width * translate_value, height * translate_value\n",
    "    tx, ty = width / width_translate, height / height_translate\n",
    "    translation_matrix = np.array([[1, 0, tx], [0, 1, ty]], dtype=np.float32)\n",
    "    \n",
    "    translated_image = cv.warpAffine(src=image, M=translation_matrix, dsize=(width, height))\n",
    "    translated_mask = cv.warpAffine(src=mask, M=translation_matrix, dsize=(width, height))\n",
    "    \n",
    "    return translated_image, translated_mask\n",
    "\n",
    "def rotateImage(image, mask):\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    center = (width/2, height/2)\n",
    "    angle = np.random.rand() * 90\n",
    "    rotate_matrix = cv.getRotationMatrix2D(center=center, angle=angle, scale=1)\n",
    "    \n",
    "    rotated_image = cv.warpAffine(src=image, M=rotate_matrix, dsize=(width, height))\n",
    "    rotated_mask = cv.warpAffine(src=mask, M=rotate_matrix, dsize=(width, height))\n",
    "    \n",
    "    return rotated_image, rotated_mask\n",
    "\n",
    "def scaleValues(images, masks):\n",
    "    return images / 255.0, masks / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0dd4883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(images, masks, height, width, augment=False, translate=False, rotate=False):\n",
    "    images, masks = resizeImages(images, masks, height, width)\n",
    "    num_channels = 1\n",
    "    \n",
    "    images, masks = toGrayScale(images, masks)\n",
    "    \n",
    "    if augment:\n",
    "        images, masks = augmentImages(images, masks, translate, rotate)\n",
    "    \n",
    "    images, masks = np.array(images, dtype=np.float32), np.array(masks, dtype=np.float32)\n",
    "    images /= 255.0\n",
    "    masks /= 255.0\n",
    "    return images, masks, num_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fb4b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataGenerator(images, masks, batch_size, shuffle=True, train=True):\n",
    "    X, Y = images, masks\n",
    "    \n",
    "    index = 0\n",
    "    num_images = len(images)\n",
    "    indices = [*range(num_images)]\n",
    "    if shuffle:\n",
    "        random.shuffle(indices)\n",
    "    \n",
    "    while True:\n",
    "        if index >= num_images:\n",
    "            index = 0\n",
    "            if shuffle:\n",
    "                random.shuffle(indices)\n",
    "        index += 1\n",
    "        \n",
    "        for i in range(0, num_images, batch_size):\n",
    "            try:\n",
    "                x = X[indices[i:i+batch_size]]\n",
    "                y = Y[indices[i:i+batch_size]]\n",
    "            except:\n",
    "                x = X[indices[i:]]\n",
    "                y = Y[indices[i:]]\n",
    "            \n",
    "            if len(x) != batch_size or i == num_images - batch_size:\n",
    "                yield x, y, 1\n",
    "            else:\n",
    "                yield x, y, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22e1bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class convBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x.float()))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86694f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_layer = convBlock(in_channels, out_channels)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        p = self.pool(x)\n",
    "        return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7d87ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.convTranspose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv_layer = convBlock(out_channels * 2, out_channels)\n",
    "    \n",
    "    def forward(self, x, skip):\n",
    "        x = self.convTranspose(x)\n",
    "        x = torch.cat([x, skip], axis=1)\n",
    "        x = self.conv_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a05ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class U_Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encode1 = encoderBlock(1, 32)\n",
    "        self.encode2 = encoderBlock(32, 64)\n",
    "        self.encode3 = encoderBlock(64, 128)\n",
    "        self.encode4 = encoderBlock(128, 256)\n",
    "        \n",
    "        self.bottleneck = convBlock(256, 512)\n",
    "        \n",
    "        self.decode1 = decoderBlock(512, 256)\n",
    "        self.decode2 = decoderBlock(256, 128)\n",
    "        self.decode3 = decoderBlock(128, 64)\n",
    "        self.decode4 = decoderBlock(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.classify = nn.Conv2d(32, 1, kernel_size=1, padding=0)\n",
    "        self.float()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1, p1 = self.encode1(x)\n",
    "        x2, p2 = self.encode2(p1)\n",
    "        x3, p3 = self.encode3(p2)\n",
    "        x4, p4 = self.encode4(p3)\n",
    "        \n",
    "        b = self.bottleneck(p4)\n",
    "        \n",
    "        d1 = self.decode1(b, x4)\n",
    "        d2 = self.decode2(d1, x3)\n",
    "        d3 = self.decode3(d2, x2)\n",
    "        d4 = self.decode4(d3, x1)\n",
    "        \n",
    "        output = self.classify(d4)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9144d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelDefinition(model_class=U_Net, learning_rate=0.001, pretrained=True, schedule=True):\n",
    "    if pretrained:\n",
    "        model = smp.FPN(encoder_weights='imagenet', in_channels=1).to(device)\n",
    "    else:\n",
    "        model = model_class().to(device)\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    if schedule:\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=30, cooldown=10)\n",
    "        return model, loss_fn, optimizer, scheduler\n",
    "    else:\n",
    "        return model, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d53dea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingLoop(train_generator, model, loss_fn, optimizer, num_epochs, height, width, num_channels, train_batch_size, val_images, val_masks, val_batch_size, scheduler=None):\n",
    "    train_loss, val_loss = [], []\n",
    "    train_DS, val_DS = [], []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss, num_images, dice_score = 0, 0, 0\n",
    "        \n",
    "        while True:\n",
    "            X, Y, count = next(train_generator)\n",
    "            X = torch.tensor(X)\n",
    "            Y = torch.tensor(Y)\n",
    "            \n",
    "            X = torch.reshape(X, (-1, 1, height, width)).to(device)\n",
    "            Y = torch.reshape(Y, (-1, 1, height, width)).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(X)\n",
    "            sigmoid = nn.Sigmoid()\n",
    "            sigmoided_output = sigmoid(output)\n",
    "            dice_score += diceScore(sigmoided_output, Y).item()\n",
    "            \n",
    "            loss = loss_fn(output, Y)\n",
    "            epoch_loss += X.size(dim=0) * loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                       \n",
    "            num_images += X.size(dim=0)            \n",
    "            if count == 1:\n",
    "                break\n",
    "        print(f\"Loss After {epoch + 1} Epochs: {epoch_loss / num_images: .6f}\")\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(epoch_loss/num_images)\n",
    "        val_generator = dataGenerator(val_images, val_masks, val_batch_size, shuffle=False, train=False)\n",
    "        valset_loss, valset_dice_score = valLoop(val_generator, loss_fn, model, height, width, val_batch_size, called_by_train=True)\n",
    "        \n",
    "        train_loss.append(epoch_loss / num_images)\n",
    "        train_DS.append(dice_score / num_images)\n",
    "        val_loss.append(valset_loss)\n",
    "        val_DS.append(valset_dice_score)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save(model.state_dict(), r'C:\\Users\\SHAMBHAVI SHANKER\\Desktop\\wids\\FPN_with_calculated_sched' + str(epoch+1) + '_Epochs_BCEWithLogits.pt')\n",
    "    \n",
    "    return model, train_loss, train_DS, val_loss, val_DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cddce024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valLoop(val_generator, loss_fn, model, height, width, val_batch_size, called_by_train=False):\n",
    "    Y_pred = []\n",
    "    num_images, loss, dice_score = 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        while True:\n",
    "            X, Y, count = next(val_generator)\n",
    "            \n",
    "            X = torch.tensor(X)\n",
    "            X = torch.reshape(X, (-1, 1, height, width)).to(device)\n",
    "            Y = torch.tensor(Y)\n",
    "            Y = torch.reshape(Y, (-1, 1, height, width)).to(device)\n",
    "            \n",
    "            Y_output = model(X)\n",
    "            num_images += X.size(dim=0)\n",
    "            loss += loss_fn(Y_output, Y).item() * X.size(dim=0)\n",
    "            \n",
    "            Y_output = torch.reshape(Y_output, (-1, height, width, 1))\n",
    "            sigmoid = nn.Sigmoid()\n",
    "            Y_output = sigmoid(Y_output)\n",
    "            dice_score += diceScore(Y_output, Y)\n",
    "            \n",
    "            Y_pred += list(np.reshape(Y_output.detach().cpu().numpy(), (-1, height, width)))\n",
    "            \n",
    "            if count == 1:\n",
    "                break\n",
    "    \n",
    "    if called_by_train:\n",
    "        return loss / num_images, dice_score / num_images\n",
    "    else:\n",
    "        return Y_pred, dice_score / num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "325c4de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diceScore(Y_output, Y):\n",
    "    gamma = 1\n",
    "    batch_size = Y_output.size(dim=0)\n",
    "    \n",
    "    model_outputs = Y_output.reshape(batch_size, -1).float()\n",
    "    original_outputs = Y.reshape(batch_size, -1).float()\n",
    "    intersection = (model_outputs * original_outputs).sum().float()\n",
    "\n",
    "    return batch_size * (2 * intersection + gamma) / (model_outputs.sum() + original_outputs.sum() + gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2ea41ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayOutputs(val_images, val_masks, Y_pred, num_show):\n",
    "    num_images = len(val_images)\n",
    "    indices = np.random.randint(0, num_images, size=num_show)\n",
    "    \n",
    "    for index in range(len(indices)):\n",
    "        cv.imshow('Grayscale Image', cv.resize(val_images[index], (256, 256)))\n",
    "        \n",
    "        cv.imshow('Original Mask', cv.resize(val_masks[index], (256, 256)))\n",
    "        cv.moveWindow('Original Mask', 300, 0)\n",
    "        \n",
    "        cv.imshow('Predicted Mask', cv.resize((Y_pred[index] * 255).astype(np.uint8), (256, 256)))\n",
    "        cv.moveWindow('Predicted Mask', 300, 300)\n",
    "        cv.waitKey(2000)\n",
    "    \n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e2c0ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path = r'C:\\Users\\SHAMBHAVI SHANKER\\Desktop\\wids\\Images\\Train'\n",
    "train_masks_path = r'C:\\Users\\SHAMBHAVI SHANKER\\Desktop\\wids\\GT\\gt_train'\n",
    "\n",
    "val_test_images_path = r'C:\\Users\\SHAMBHAVI SHANKER\\Desktop\\wids\\Images\\validate'\n",
    "val_test_masks_path = r'C:\\Users\\SHAMBHAVI SHANKER\\Desktop\\wids\\GT\\gt_validate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af912e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 64, 64\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 200\n",
    "\n",
    "train_batch_size, val_batch_size, test_batch_size = 16, 8, 8\n",
    "val_fraction = 1.0\n",
    "shuffle = True\n",
    "\n",
    "augment = True\n",
    "translate, rotate = True, True\n",
    "\n",
    "num_show = 10\n",
    "pretrain = True\n",
    "schedule = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e66350c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:05<00:00, 149.79it/s]\n",
      "100%|██████████| 800/800 [00:02<00:00, 364.91it/s]\n",
      "100%|██████████| 200/200 [00:01<00:00, 153.99it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 434.18it/s]\n"
     ]
    }
   ],
   "source": [
    "train_images, train_masks, val_images, val_masks, test_images, test_masks = allAboutData(train_images_path, train_masks_path, val_test_images_path, val_test_masks_path, val_fraction=val_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19047411",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_masks, train_num_channels = preProcess(train_images, train_masks, height, width, augment=augment, translate=translate, rotate=rotate)\n",
    "val_images, val_masks, val_num_channels = preProcess(val_images, val_masks, height, width)\n",
    "test_images, test_masks, test_num_channels = preProcess(test_images, test_masks, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5dc3613",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = dataGenerator(train_images, train_masks, train_batch_size, shuffle=shuffle, train=True)\n",
    "val_generator = dataGenerator(val_images, val_masks, val_batch_size, shuffle=False, train=False)\n",
    "test_generator = dataGenerator(test_images, test_masks, test_batch_size, shuffle=False, train=False)\n",
    "valUsingTrain_generator = dataGenerator(train_images, train_masks, val_batch_size, shuffle=False, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42052943",
   "metadata": {},
   "outputs": [],
   "source": [
    "if schedule:\n",
    "    model, loss_fn, optimizer, scheduler = modelDefinition(model_class=U_Net, learning_rate=learning_rate, pretrained=pretrain, schedule=schedule)\n",
    "else:\n",
    "    model, loss_fn, optimizer = modelDefinition(model_class=U_Net, learning_rate=learning_rate, pretrained=pretrain, schedule=schedule)\n",
    "    scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93435a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPN(\n",
      "  (encoder): ResNetEncoder(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): FPNDecoder(\n",
      "    (p5): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p4): FPNBlock(\n",
      "      (skip_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (p3): FPNBlock(\n",
      "      (skip_conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (p2): FPNBlock(\n",
      "      (skip_conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (seg_blocks): ModuleList(\n",
      "      (0): SegmentationBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv3x3GNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Conv3x3GNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv3x3GNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): SegmentationBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv3x3GNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Conv3x3GNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): SegmentationBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv3x3GNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): SegmentationBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv3x3GNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (merge): MergeBlock()\n",
      "    (dropout): Dropout2d(p=0.2, inplace=True)\n",
      "  )\n",
      "  (segmentation_head): SegmentationHead(\n",
      "    (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): UpsamplingBilinear2d(scale_factor=4.0, mode=bilinear)\n",
      "    (2): Activation(\n",
      "      (activation): Identity()\n",
      "    )\n",
      "  )\n",
      ") <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x000002023F225A50>\n"
     ]
    }
   ],
   "source": [
    "print(model, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0c61665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss After 1 Epochs:  0.419331\n",
      "Loss After 2 Epochs:  0.335652\n",
      "Loss After 3 Epochs:  0.289792\n",
      "Loss After 4 Epochs:  0.256164\n",
      "Loss After 5 Epochs:  0.232426\n",
      "Loss After 6 Epochs:  0.210211\n",
      "Loss After 7 Epochs:  0.196165\n",
      "Loss After 8 Epochs:  0.183457\n",
      "Loss After 9 Epochs:  0.171533\n",
      "Loss After 10 Epochs:  0.167313\n",
      "Loss After 11 Epochs:  0.161611\n",
      "Loss After 12 Epochs:  0.155066\n",
      "Loss After 13 Epochs:  0.148315\n",
      "Loss After 14 Epochs:  0.143190\n",
      "Loss After 15 Epochs:  0.139839\n",
      "Loss After 16 Epochs:  0.134074\n",
      "Loss After 17 Epochs:  0.126430\n",
      "Loss After 18 Epochs:  0.123380\n",
      "Loss After 19 Epochs:  0.120286\n",
      "Loss After 20 Epochs:  0.117265\n",
      "Loss After 21 Epochs:  0.116655\n",
      "Loss After 22 Epochs:  0.112162\n",
      "Loss After 23 Epochs:  0.111009\n",
      "Loss After 24 Epochs:  0.107482\n",
      "Loss After 25 Epochs:  0.103778\n",
      "Loss After 26 Epochs:  0.100873\n",
      "Loss After 27 Epochs:  0.099836\n",
      "Loss After 28 Epochs:  0.099252\n",
      "Loss After 29 Epochs:  0.096918\n",
      "Loss After 30 Epochs:  0.094130\n",
      "Loss After 31 Epochs:  0.092326\n",
      "Loss After 32 Epochs:  0.089586\n",
      "Loss After 33 Epochs:  0.087481\n",
      "Loss After 34 Epochs:  0.084656\n",
      "Loss After 35 Epochs:  0.083167\n",
      "Loss After 36 Epochs:  0.082576\n",
      "Loss After 37 Epochs:  0.082332\n",
      "Loss After 38 Epochs:  0.082042\n",
      "Loss After 39 Epochs:  0.081892\n",
      "Loss After 40 Epochs:  0.078804\n",
      "Loss After 41 Epochs:  0.077176\n",
      "Loss After 42 Epochs:  0.075763\n",
      "Loss After 43 Epochs:  0.074161\n",
      "Loss After 44 Epochs:  0.072559\n",
      "Loss After 45 Epochs:  0.071551\n",
      "Loss After 46 Epochs:  0.072006\n",
      "Loss After 47 Epochs:  0.071040\n",
      "Loss After 48 Epochs:  0.070390\n",
      "Loss After 49 Epochs:  0.070432\n",
      "Loss After 50 Epochs:  0.070766\n",
      "Loss After 51 Epochs:  0.068871\n",
      "Loss After 52 Epochs:  0.066967\n",
      "Loss After 53 Epochs:  0.065708\n",
      "Loss After 54 Epochs:  0.064555\n",
      "Loss After 55 Epochs:  0.064370\n",
      "Loss After 56 Epochs:  0.064268\n",
      "Loss After 57 Epochs:  0.064507\n",
      "Loss After 58 Epochs:  0.063764\n",
      "Loss After 59 Epochs:  0.062376\n",
      "Loss After 60 Epochs:  0.061475\n",
      "Loss After 61 Epochs:  0.061357\n",
      "Loss After 62 Epochs:  0.061111\n",
      "Loss After 63 Epochs:  0.060564\n",
      "Loss After 64 Epochs:  0.060448\n",
      "Loss After 65 Epochs:  0.059941\n",
      "Loss After 66 Epochs:  0.059549\n",
      "Loss After 67 Epochs:  0.059042\n",
      "Loss After 68 Epochs:  0.058771\n",
      "Loss After 69 Epochs:  0.058374\n",
      "Loss After 70 Epochs:  0.057352\n",
      "Loss After 71 Epochs:  0.056649\n",
      "Loss After 72 Epochs:  0.056613\n",
      "Loss After 73 Epochs:  0.056549\n",
      "Loss After 74 Epochs:  0.056041\n",
      "Loss After 75 Epochs:  0.055455\n",
      "Loss After 76 Epochs:  0.055112\n",
      "Loss After 77 Epochs:  0.054539\n",
      "Loss After 78 Epochs:  0.054323\n",
      "Loss After 79 Epochs:  0.053908\n",
      "Loss After 80 Epochs:  0.053912\n",
      "Loss After 81 Epochs:  0.053165\n",
      "Loss After 82 Epochs:  0.052685\n",
      "Loss After 83 Epochs:  0.051986\n",
      "Loss After 84 Epochs:  0.051481\n",
      "Loss After 85 Epochs:  0.051502\n",
      "Loss After 86 Epochs:  0.051361\n",
      "Loss After 87 Epochs:  0.051443\n",
      "Loss After 88 Epochs:  0.051394\n",
      "Loss After 89 Epochs:  0.051199\n",
      "Loss After 90 Epochs:  0.051119\n",
      "Loss After 91 Epochs:  0.050888\n",
      "Loss After 92 Epochs:  0.050237\n",
      "Loss After 93 Epochs:  0.049993\n",
      "Loss After 94 Epochs:  0.049624\n",
      "Loss After 95 Epochs:  0.049098\n",
      "Loss After 96 Epochs:  0.049158\n",
      "Loss After 97 Epochs:  0.049140\n",
      "Loss After 98 Epochs:  0.048785\n",
      "Loss After 99 Epochs:  0.048593\n",
      "Loss After 100 Epochs:  0.048355\n",
      "Loss After 101 Epochs:  0.047932\n",
      "Loss After 102 Epochs:  0.047842\n",
      "Loss After 103 Epochs:  0.047246\n",
      "Loss After 104 Epochs:  0.046854\n",
      "Loss After 105 Epochs:  0.046611\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model, train_loss, train_DS, val_loss, val_DS \u001b[39m=\u001b[39m trainingLoop(train_generator, model, loss_fn, optimizer, num_epochs, height, width, train_num_channels, train_batch_size, val_images, val_masks, val_batch_size, scheduler)\n",
      "Cell \u001b[1;32mIn[36], line 18\u001b[0m, in \u001b[0;36mtrainingLoop\u001b[1;34m(train_generator, model, loss_fn, optimizer, num_epochs, height, width, num_channels, train_batch_size, val_images, val_masks, val_batch_size, scheduler)\u001b[0m\n\u001b[0;32m     14\u001b[0m Y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mreshape(Y, (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, height, width))\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     16\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 18\u001b[0m output \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m     19\u001b[0m sigmoid \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSigmoid()\n\u001b[0;32m     20\u001b[0m sigmoided_output \u001b[39m=\u001b[39m sigmoid(output)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\segmentation_models_pytorch\\base\\model.py:29\u001b[0m, in \u001b[0;36mSegmentationModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39m\"\"\"Sequentially pass `x` trough model`s encoder, decoder and heads\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_input_shape(x)\n\u001b[1;32m---> 29\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[0;32m     30\u001b[0m decoder_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(\u001b[39m*\u001b[39mfeatures)\n\u001b[0;32m     32\u001b[0m masks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msegmentation_head(decoder_output)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\segmentation_models_pytorch\\encoders\\resnet.py:62\u001b[0m, in \u001b[0;36mResNetEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     60\u001b[0m features \u001b[39m=\u001b[39m []\n\u001b[0;32m     61\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m---> 62\u001b[0m     x \u001b[39m=\u001b[39m stages[i](x)\n\u001b[0;32m     63\u001b[0m     features\u001b[39m.\u001b[39mappend(x)\n\u001b[0;32m     65\u001b[0m \u001b[39mreturn\u001b[39;00m features\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\resnet.py:96\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     93\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(out)\n\u001b[0;32m     94\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[1;32m---> 96\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(out)\n\u001b[0;32m     97\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(out)\n\u001b[0;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsample \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, train_loss, train_DS, val_loss, val_DS = trainingLoop(train_generator, model, loss_fn, optimizer, num_epochs, height, width, train_num_channels, train_batch_size, val_images, val_masks, val_batch_size, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5229ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [*range(len(train_loss))]\n",
    "val_DS = [val_DS[i] * val_batch_size for i in range(len(val_DS))]\n",
    "plt.plot(X, val_DS)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Validation Dice Score')\n",
    "plt.savefig(r'C:\\Users\\SHAMBHAVI SHANKER\\Desktop\\wids\\FPN_with_calculated_sched\\Val_DS_FPN_GRAY.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f540bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [*range(len(train_loss))]\n",
    "train_DS = [train_DS[i] * train_batch_size for i in range(len(train_DS))]\n",
    "plt.plot(X, train_DS)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Train Dice Score')\n",
    "plt.savefig(r'C:\\Users\\SHAMBHAVI SHANKER\\Desktop\\wids\\FPN_with_calculated_sched\\Train_DS_FPN_GRAY.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd903a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [*range(len(train_loss))]\n",
    "plt.plot(X, train_loss)\n",
    "plt.plot(X, val_loss)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend((['Train Loss', 'Val Loss']))\n",
    "plt.savefig(r'C:\\Users\\SHAMBHAVI SHANKER\\Desktop\\wids\\FPN_with_calculated_sched\\Train_Val_Loss_FPN_GRAY.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [*range(len(train_loss))]\n",
    "plt.plot(X, val_loss)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.savefig(r'C:\\Users\\SHAMBHAVI SHANKER\\Desktop\\wids\\FPN_with_calculated_sched\\Val_Loss_FPN_GRAY.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb41df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [*range(len(train_loss))]\n",
    "plt.plot(X, train_loss)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.savefig(r'C:\\Users\\SHAMBHAVI SHANKER\\Desktop\\wids\\FPN_with_calculated_sched\\Train_Loss_FPN_GRAY.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a2dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_DS, val_loss, val_DS = fixLists(train_loss), fixLists(train_DS), fixLists(val_loss), fixLists(val_DS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1d606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixLists(input_list):\n",
    "    fixed_list = []\n",
    "    for elem in input_list:\n",
    "        try:\n",
    "            fixed_list.append(elem.detach().cpu().item())\n",
    "        except:\n",
    "            fixed_list.append(elem)\n",
    "    return fixed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736eb624",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred, dice_score = valLoop(val_generator, loss_fn, model, height, width, val_batch_size, called_by_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd15a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "displayOutputs(val_images, val_masks, Y_pred, num_show=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
